# -*- coding: utf-8 -*-
"""Cancer_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kwH-XGnEE9nDviQ_fYs7ecDCcrekpv-6

import dependencies
"""

#data handling
import pandas as pd
import numpy as np

#data visualization
import matplotlib.pyplot as plt
import seaborn as sns

#preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import label_binarize
from sklearn.preprocessing import MinMaxScaler

#feature selection
from sklearn.feature_selection import mutual_info_classif

#classification
from sklearn.multiclass import OneVsRestClassifier
from sklearn.ensemble import RandomForestClassifier

# performance metrics
from sklearn.metrics import balanced_accuracy_score,f1_score,precision_score, recall_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
# Import ConfusionMatrixDisplay instead of plot_confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve,auc
from sklearn.metrics import roc_auc_score

"""load data"""

#read data directly from a github repository

file_url='https://github.com/vappiah/Machine-Learning-Tutorials/raw/main/datasets/cancer_gene_expression.zip'

df=pd.read_csv(file_url)

df

#let's check the number of samples and features
#note:the last column contain the labels. it is not considered as a feature

print(df.shape)

#let's check some of the columns (first, second and third columns)
print(df.columns[0:3])

#lets check the name of the last column of this dataframe

df.columns[-1]

#check for missing values
datanul=df.isnull().sum()
g=[i for i in datanul if i>0]

print('columns with missing values:%d'%len(g))

#let's check how many different cancer types are there in the data
#note: in this tutorial the cancer types will be referred to as classes or labels

print(df['Cancer_Type'].value_counts())

"""| Abbreviation | Full Form                             |
| ------------ | ------------------------------------- |
| **BRCA**     | **Breast Invasive Carcinoma**         |
| **KIRC**     | **Kidney Renal Clear Cell Carcinoma** |
| **LUAD**     | **Lung Adenocarcinoma**               |
| **PRAD**     | **Prostate Adenocarcinoma**           |
| **COAD**     | **Colon Adenocarcinoma**              |

"""

#plot a bar chat to display the class distribution
df['Cancer_Type'].value_counts().plot.bar()

#we will now seperate the feature values from the class. we do this because scikit-learn requires that features and class are separated before parsing them to the classifiers.

X=df.iloc[:,0:-1]
y=df.iloc[:,-1]

X.shape

y.shape

#let's encode target labels (y) with values between 0 and n_classes-1.
#encoding will be done using the LabelEncoder
label_encoder=LabelEncoder()
label_encoder.fit(y)
y_encoded=label_encoder.transform(y)
labels=label_encoder.classes_
classes=np.unique(y_encoded)

labels

classes

#split data into training and test sets
X_train,X_test,y_train,y_test=train_test_split(X,y_encoded,test_size=0.2,random_state=42)

df.iloc[:,0:10].describe()

df.shape

# scale data between 0 and 1

min_max_scaler=MinMaxScaler()
X_train_norm=min_max_scaler.fit_transform(X_train)
X_test_norm=min_max_scaler.fit_transform(X_test)

len(X_train_norm)

len(X_test_norm)

MI=mutual_info_classif(X_train_norm,y_train)

#select top n features. lets say 300.
#you can modify the value and see how the performance of the model changes

n_features=300
selected_scores_indices=np.argsort(MI)[::-1][0:n_features]

X_train_selected=X_train_norm[:,selected_scores_indices]
X_test_selected=X_test_norm[:,selected_scores_indices]

X_train_selected.shape

X_test_selected.shape

#Random Forest Classifier
#because we are dealing with multiclass data, the one versus rest strategy is used.
#learn to predict each class against the other.

RF=OneVsRestClassifier(RandomForestClassifier(max_features=0.2))
RF.fit(X_train_selected,y_train)
y_pred =RF.predict(X_test_selected)
pred_prob = RF.predict_proba(X_test_selected)

#accuracy
accuracy=np.round(balanced_accuracy_score(y_test,y_pred),4)
print('accuracy:%0.4f'%accuracy)

#precision
precision=np.round(precision_score(y_test,y_pred,average = 'weighted'),4)
print('precision:%0.4f'%precision)

#recall
recall=np.round(recall_score(y_test,y_pred,average = 'weighted'),4)
print('recall:%0.4f'%recall)

#f1score
f1score=np.round(f1_score(y_test,y_pred,average = 'weighted'),4)
print('f1score:%0.4f'%f1score)


report=classification_report(y_test,y_pred, target_names=labels)
print('\n')
print('classification report\n\n')
print(report)

#generate confusion matrix
cm=confusion_matrix(y_test,y_pred)
cm_df=pd.DataFrame(cm,index=labels,columns=labels)

cm_df

#visualize the confusion matrix using seaborn

sns.heatmap(cm_df,annot=True,cmap='Blues')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')

#visualize the confusion matrix directly
disp = ConfusionMatrixDisplay.from_estimator(RF, X_test_selected, y_test, xticks_rotation='vertical', cmap='Blues', display_labels=labels)

#roc curves will be generated for each class
#we will therefore have to binarize the y_test labels
#this is done because the probabilities(pred_prob) are calculated for each each class
#we therefore need to put the y_test label in the same format as the pred_prob
y_test_binarized=label_binarize(y_test,classes=classes)

# roc curve for classes
fpr = {}
tpr = {}
thresh ={}
roc_auc = dict()

n_class = classes.shape[0]

for i in range(n_class):
    fpr[i], tpr[i], thresh[i] = roc_curve(y_test_binarized[:,i], pred_prob[:,i])
    roc_auc[i] = auc(fpr[i], tpr[i])

    # plotting
    plt.plot(fpr[i], tpr[i], linestyle='--',
             label='%s vs Rest (AUC=%0.2f)'%(labels[i],roc_auc[i]))

plt.plot([0,1],[0,1],'b--')
plt.xlim([0,1])
plt.ylim([0,1.05])
plt.title('Multiclass ROC curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive rate')
plt.legend(loc='lower right')
plt.show()

import joblib

joblib.dump(RF, 'rf_model.pkl')
joblib.dump(min_max_scaler, 'scaler.pkl')
joblib.dump(label_encoder, 'label_encoder.pkl')
joblib.dump(selected_scores_indices, 'selected_features.pkl')

!pip install gradio

import gradio as gr
import numpy as np
import joblib

# Load the saved model components
model = joblib.load('rf_model.pkl')                   # Trained OneVsRestClassifier
scaler = joblib.load('scaler.pkl')                    # Trained MinMaxScaler
label_encoder = joblib.load('label_encoder.pkl')      # Fitted LabelEncoder
selected_indices = joblib.load('selected_features.pkl')  # Top 300 feature indices

# Prediction function: accepts a sequence of gene expression values
def predict_cancer_from_sequence(seq):
    try:
        # Convert comma-separated string to float list
        values = list(map(float, seq.strip().split(',')))

        # Check if length matches expected feature count
        if len(values) != len(scaler.feature_names_in_):
            return f"‚ö†Ô∏è Expected {len(scaler.feature_names_in_)} values, but got {len(values)}"

        # Convert to numpy array and reshape
        input_array = np.array(values).reshape(1, -1)

        # Scale and select top features
        input_scaled = scaler.transform(input_array)
        input_selected = input_scaled[:, selected_indices]

        # Predict
        prediction = model.predict(input_selected)
        predicted_class = label_encoder.inverse_transform(prediction)

        return f"üß¨ Predicted Cancer Type: {predicted_class[0]}"

    except Exception as e:
        return f"‚ùå Error: {str(e)}"

# Gradio Interface
gr.Interface(
    fn=predict_cancer_from_sequence,
    inputs=gr.Textbox(
        label="Enter Gene Expression Sequence (comma-separated)",
        placeholder="1.23, 0.87, 0.56, ..., 0.94"
    ),
    outputs="text",
    title="Cancer Type Prediction from Gene Expression",
    description="Paste gene expression values (20531 total, comma-separated).",
).launch(share=True)

import pandas as pd
import numpy as np

# Load the CSV file
df = pd.read_csv("/content/cancer_gene_expression.csv")

# Get the second row (index 1), excluding the label column
row_values = df.iloc[2, :-1].values

# Convert to comma-separated string
formatted_row = ', '.join(map(str, row_values))

print(formatted_row)

import heapq

# Create a min-heap
heap = []
heapq.heappush(heap, -3)
heapq.heappush(heap, -1)
heapq.heappush(heap, -5)
heapq.heappush(heap, -2)

print(heap)  # [1, 2, 5, 3]

# Pop smallest element
print(-heapq.heappop(heap))  # 1

